{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from yolox.exp import get_exp\n",
    "from yolox.utils import fuse_model, get_model_info, postprocess, postprocess_object_pose, vis\n",
    "from yolox.utils.object_pose_utils  import decode_rotation_translation\n",
    "from yolox.utils.plots import plot_one_box, colors\n",
    "from yolox.data.data_augment import ValTransform\n",
    "from yolox.data.datasets import YCBV_CLASSES\n",
    "import time\n",
    "import copy\n",
    "from loguru import logger\n",
    "\n",
    "model_root_path = \"models/small\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"mps\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#camera_matrix for test-split of ycbv dataset\n",
    "ycbv_camera_matrix = np.array([[1066.778, 0, 312.9869],\n",
    "                              [0.0, 1067.487, 241.3109],\n",
    "                              [0.0, 0.0, 1.0]], dtype=np.float32)\n",
    "\n",
    "_COLORS = np.array(\n",
    "    [\n",
    "        0.000, 0.447, 0.741,\n",
    "        0.850, 0.325, 0.098,\n",
    "        0.929, 0.694, 0.125,\n",
    "        0.494, 0.184, 0.556,\n",
    "        0.466, 0.674, 0.188,\n",
    "        0.301, 0.745, 0.933,\n",
    "        0.635, 0.078, 0.184,\n",
    "        0.300, 0.300, 0.300,\n",
    "        0.600, 0.600, 0.600,\n",
    "        1.000, 0.000, 0.000,\n",
    "        1.000, 0.500, 0.000,\n",
    "        0.749, 0.749, 0.000,\n",
    "        0.000, 1.000, 0.000,\n",
    "        0.000, 0.000, 1.000,\n",
    "        0.667, 0.000, 1.000,\n",
    "        0.333, 0.333, 0.000,\n",
    "        0.333, 0.667, 0.000,\n",
    "        0.333, 1.000, 0.000,\n",
    "        0.667, 0.333, 0.000,\n",
    "        0.667, 0.667, 0.000,\n",
    "        0.667, 1.000, 0.000,\n",
    "        1.000, 0.333, 0.000,\n",
    "        1.000, 0.667, 0.000,\n",
    "        1.000, 1.000, 0.000,\n",
    "        0.000, 0.333, 0.500,\n",
    "        0.000, 0.667, 0.500,\n",
    "        0.000, 1.000, 0.500,\n",
    "        0.333, 0.000, 0.500,\n",
    "        0.333, 0.333, 0.500,\n",
    "        0.333, 0.667, 0.500,\n",
    "        0.333, 1.000, 0.500,\n",
    "        0.667, 0.000, 0.500,\n",
    "        0.667, 0.333, 0.500,\n",
    "        0.667, 0.667, 0.500,\n",
    "        0.667, 1.000, 0.500,\n",
    "        1.000, 0.000, 0.500,\n",
    "        1.000, 0.333, 0.500,\n",
    "        1.000, 0.667, 0.500,\n",
    "        1.000, 1.000, 0.500,\n",
    "        0.000, 0.333, 1.000,\n",
    "        0.000, 0.667, 1.000,\n",
    "        0.000, 1.000, 1.000,\n",
    "        0.333, 0.000, 1.000,\n",
    "        0.333, 0.333, 1.000,\n",
    "        0.333, 0.667, 1.000,\n",
    "        0.333, 1.000, 1.000,\n",
    "        0.667, 0.000, 1.000,\n",
    "        0.667, 0.333, 1.000,\n",
    "        0.667, 0.667, 1.000,\n",
    "        0.667, 1.000, 1.000,\n",
    "        1.000, 0.000, 1.000,\n",
    "        1.000, 0.333, 1.000,\n",
    "        1.000, 0.667, 1.000,\n",
    "        0.333, 0.000, 0.000,\n",
    "        0.500, 0.000, 0.000,\n",
    "        0.667, 0.000, 0.000,\n",
    "        0.833, 0.000, 0.000,\n",
    "        1.000, 0.000, 0.000,\n",
    "        0.000, 0.167, 0.000,\n",
    "        0.000, 0.333, 0.000,\n",
    "        0.000, 0.500, 0.000,\n",
    "        0.000, 0.667, 0.000,\n",
    "        0.000, 0.833, 0.000,\n",
    "        0.000, 1.000, 0.000,\n",
    "        0.000, 0.000, 0.167,\n",
    "        0.000, 0.000, 0.333,\n",
    "        0.000, 0.000, 0.500,\n",
    "        0.000, 0.000, 0.667,\n",
    "        0.000, 0.000, 0.833,\n",
    "        0.000, 0.000, 1.000,\n",
    "        0.000, 0.000, 0.000,\n",
    "        0.143, 0.143, 0.143,\n",
    "        0.286, 0.286, 0.286,\n",
    "        0.429, 0.429, 0.429,\n",
    "        0.571, 0.571, 0.571,\n",
    "        0.714, 0.714, 0.714,\n",
    "        0.857, 0.857, 0.857,\n",
    "        0.000, 0.447, 0.741,\n",
    "        0.314, 0.717, 0.741,\n",
    "        0.50, 0.5, 0\n",
    "    ]\n",
    ").astype(np.float32).reshape(-1, 3)\n",
    "\n",
    "\n",
    "#vertices for ycbv21 objects\n",
    "ycbv_vertices = np.array([\n",
    "    [51.1445, 51.223, 70.072],\n",
    "    [35.865, 81.9885, 106.743],\n",
    "    [24.772, 47.024, 88.0075],\n",
    "    [33.927, 33.875, 51.0185],\n",
    "    [48.575, 33.31, 95.704],\n",
    "    [42.755, 42.807, 16.7555],\n",
    "    [68.924, 64.3955, 19.414],\n",
    "    [44.6775, 50.5545, 15.06],\n",
    "    [51.0615, 30.161, 41.8185],\n",
    "    [54.444, 89.206, 18.335],\n",
    "    [74.4985, 72.3845, 121.32],\n",
    "    [51.203, 33.856, 125.32],\n",
    "    [80.722, 80.5565, 27.485],\n",
    "    [58.483, 46.5375, 40.692],\n",
    "    [92.1205, 93.717, 28.6585],\n",
    "    [51.9755, 51.774, 102.945],\n",
    "    [48.04, 100.772, 7.858],\n",
    "    [10.5195, 60.4225, 9.4385],\n",
    "    [59.978, 85.639, 19.575],\n",
    "    [104.897, 82.18, 18.1665],\n",
    "    [26.315, 38.921, 25.5655,]\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "vertices_order = np.array([\n",
    "            [-1, -1, -1],\n",
    "            [-1, -1, 1],\n",
    "            [-1, 1,  1],\n",
    "            [-1, 1, -1],\n",
    "            [1, -1, -1],\n",
    "            [1, -1,  1],\n",
    "            [1,  1,  1],\n",
    "            [1,  1, -1],\n",
    "            ], dtype=np.float32)\n",
    "\n",
    "# camera_matrix for logitech c270 ->640x480\n",
    "logitech_camera_matrix_resize = np.array([[1066.778, 0.0, 312.9869],\n",
    "                                          [0.0, 1066.778, 241.3109],\n",
    "                                          [0.0, 0.0, 1.0]], dtype=np.float32)\n",
    "\n",
    "def project_3d_2d(pts_3d, rotation_mat, translation_vec, camera_matrix):\n",
    "    xformed_3d = np.matmul(pts_3d, rotation_mat.T) + translation_vec\n",
    "    xformed_3d[:,:3] = xformed_3d[:,:3]/xformed_3d[:,2:3]\n",
    "    projected_2d = np.matmul(xformed_3d, camera_matrix.reshape((3, 3)).T)[:, :2]\n",
    "    return projected_2d\n",
    "\n",
    "def draw_bbox_2d(origin_img, dets, class_names, conf_thres=0.85):\n",
    "    if len(dets.shape) > 2:\n",
    "        dets = dets[0][0]\n",
    "\n",
    "    for det in dets:\n",
    "        box, score, cls = det[:4], det[4], int(det[5])\n",
    "        print(box)\n",
    "        if score>conf_thres:\n",
    "            cls_id = int(cls)\n",
    "            x0, y0 = int(box[0]), int(box[1])\n",
    "            x1, y1 = int(box[2]), int(box[3])\n",
    "            color = (_COLORS[cls] * 255).astype(np.uint8).tolist()\n",
    "            cv2.rectangle(origin_img, (x0, y0), (x1, y1), color, 2)\n",
    "                    #Labels on cuboid\n",
    "            text = '{}:{:.1f}%'.format(class_names[cls], score * 100)\n",
    "            txt_color = (0, 0, 0) if np.mean(_COLORS[cls]) > 0.5 else (255, 255, 255)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            txt_size = cv2.getTextSize(text, font, 0.4, 1)[0]\n",
    "            txt_bk_color = (_COLORS[cls] * 255 * 0.7).astype(np.uint8).tolist()\n",
    "            x0, y0 = int(box[0]), int(box[1])\n",
    "            cv2.rectangle(\n",
    "                origin_img,\n",
    "                (x0, y0 + 1),\n",
    "                (x0 + txt_size[0] + 1, y0 + int(1.5*txt_size[1])),\n",
    "                txt_bk_color,\n",
    "                -1\n",
    "            )\n",
    "            cv2.putText(origin_img, text, (x0, y0 + txt_size[1]), font, 0.4, txt_color, thickness=1)\n",
    "    return origin_img\n",
    "\n",
    "def draw_obj_pose(origin_img, dets, class_names, class_to_cuboid, camera_matrix, conf_thres=0.85):\n",
    "    if len(dets.shape) > 2:\n",
    "        dets = dets[0][0]\n",
    "\n",
    "    for det in dets:\n",
    "        box, score, cls = det[:4], det[4], int(det[5])\n",
    "        if score>conf_thres:\n",
    "            color = (_COLORS[cls] * 255).astype(np.uint8).tolist()\n",
    "            r1, r2 = det[6:9, None], det[9:12, None]\n",
    "            r3 = np.cross(r1, r2, axis=0)\n",
    "            rotation_mat = np.concatenate((r1, r2, r3), axis=1)\n",
    "            translation_vec = det[12:15]\n",
    "            tx = translation_vec[0]\n",
    "            ty = translation_vec[1]\n",
    "            tz = translation_vec[2]\n",
    "            x = camera_matrix[0,2] + camera_matrix[0,0] *tx/tz\n",
    "            y = camera_matrix[1,2] + camera_matrix[1,1] *ty/tz\n",
    "            X = (x - logitech_camera_matrix_resize[0,2])*tz/logitech_camera_matrix_resize[0,0]\n",
    "            Y = (y - logitech_camera_matrix_resize[1,2])*tz/logitech_camera_matrix_resize[1,1]\n",
    "            translation_vec[0] = X\n",
    "            translation_vec[1] = Y\n",
    "            cuboid_corners_2d = project_3d_2d(class_to_cuboid[int(cls)], rotation_mat, translation_vec, camera_matrix)\n",
    "            draw_cuboid_2d(img=origin_img, cuboid_corners=cuboid_corners_2d, color=color)\n",
    "\n",
    "            #Labels on cuboid\n",
    "            text = '{}:{:.1f}%'.format(class_names[cls], score * 100)\n",
    "            txt_color = (0, 0, 0) if np.mean(_COLORS[cls]) > 0.5 else (255, 255, 255)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            txt_size = cv2.getTextSize(text, font, 0.4, 1)[0]\n",
    "            txt_bk_color = (_COLORS[cls] * 255 * 0.7).astype(np.uint8).tolist()\n",
    "            x0, y0 = int(box[0]), int(box[1])\n",
    "            cv2.rectangle(\n",
    "                origin_img,\n",
    "                (x0, y0 + 1),\n",
    "                (x0 + txt_size[0] + 1, y0 + int(1.5*txt_size[1])),\n",
    "                txt_bk_color,\n",
    "                -1\n",
    "            )\n",
    "            cv2.putText(origin_img, text, (x0, y0 + txt_size[1]), font, 0.4, txt_color, thickness=1)\n",
    "    return origin_img\n",
    "\n",
    "def draw_cuboid_2d(img, cuboid_corners, color = (0, 255, 0), thickness = 2):\n",
    "    box = np.copy(cuboid_corners).astype(np.int32)\n",
    "    box = [tuple(kpt) for kpt in box]\n",
    "    #front??? to check\n",
    "    cv2.line(img, box[0], box[1], color, thickness)\n",
    "    cv2.line(img, box[1], box[2], color, thickness)\n",
    "    cv2.line(img, box[2], box[3], color, thickness)\n",
    "    cv2.line(img, box[0], box[3], color, thickness)\n",
    "    #back\n",
    "    cv2.line(img, box[4], box[5], color, thickness)\n",
    "    cv2.line(img, box[5], box[6], color, thickness)\n",
    "    cv2.line(img, box[6], box[7], color, thickness)\n",
    "    cv2.line(img, box[4], box[7], color, thickness)\n",
    "    #sides\n",
    "    cv2.line(img, box[0], box[4], color, thickness)\n",
    "    cv2.line(img, box[1], box[5], color, thickness)\n",
    "    cv2.line(img, box[2], box[6], color, thickness)\n",
    "    cv2.line(img, box[3], box[7], color, thickness)\n",
    "    return img\n",
    "\n",
    "class Predictor(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        exp,\n",
    "        cls_names=YCBV_CLASSES,\n",
    "        trt_file=None,\n",
    "        decoder=None,\n",
    "        device=\"cpu\",\n",
    "        fp16=False,\n",
    "        legacy=False,\n",
    "        task=\"2dod\",\n",
    "        data_set=\"coco\"\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.cls_names = cls_names\n",
    "        self.decoder = decoder\n",
    "        self.num_classes = exp.num_classes\n",
    "        self.confthre = exp.test_conf\n",
    "        self.nmsthre = exp.nmsthre\n",
    "        self.test_size = exp.test_size\n",
    "        self.device = device\n",
    "        self.fp16 = fp16\n",
    "        self.preproc = ValTransform(legacy=legacy)\n",
    "        self.task = task\n",
    "        self.data_set = data_set\n",
    "        self.cad_models = model.head.cad_models\n",
    "        \"\"\"if trt_file is not None:\n",
    "            from torch2trt import TRTModule\n",
    "\n",
    "            model_trt = TRTModule()\n",
    "            model_trt.load_state_dict(torch.load(trt_file))\n",
    "\n",
    "            x = torch.ones(1, 3, exp.test_size[0], exp.test_size[1]).cuda()\n",
    "            self.model(x)\n",
    "            self.model = model_trt \"\"\"\n",
    "\n",
    "    def inference(self, img):\n",
    "        img_info = {\"id\": 0}\n",
    "        if isinstance(img, str):\n",
    "            img_info[\"file_name\"] = os.path.basename(img)\n",
    "            img = cv2.imread(img)\n",
    "        else:\n",
    "            img_info[\"file_name\"] = None\n",
    "\n",
    "        height, width = img.shape[:2]\n",
    "        img_info[\"height\"] = height\n",
    "        img_info[\"width\"] = width\n",
    "        img_info[\"raw_img\"] = img\n",
    "\n",
    "        ratio = min(self.test_size[0] / img.shape[0], self.test_size[1] / img.shape[1])\n",
    "        img_info[\"ratio\"] = ratio\n",
    "\n",
    "        img, _ = self.preproc(img, None, self.test_size)\n",
    "        img_info[\"img\"] = img.transpose(1, 2, 0)\n",
    "        img = torch.from_numpy(img).unsqueeze(0)\n",
    "        img = img.float()\n",
    "        if self.device == \"gpu\":\n",
    "            img = img.cuda()\n",
    "        else:\n",
    "            img = img.to(self.device)\n",
    "\n",
    "        if self.fp16:\n",
    "            img = img.half()  # to FP16   \n",
    "\n",
    "        with torch.no_grad():\n",
    "            t0 = time.time()\n",
    "            outputs = self.model(img)\n",
    "            if self.decoder is not None:\n",
    "                outputs = self.decoder(outputs, dtype=outputs.type())\n",
    "            if self.task == \"object_pose\":\n",
    "                outputs = postprocess_object_pose(\n",
    "                    outputs, self.num_classes, self.confthre,\n",
    "                    self.nmsthre, class_agnostic=True\n",
    "                )\n",
    "            else:\n",
    "                print(outputs)\n",
    "                outputs = postprocess(\n",
    "                    outputs, self.num_classes, self.confthre,\n",
    "                    self.nmsthre, class_agnostic=True\n",
    "                )\n",
    "            logger.info(\"Infer time: {:.4f}s\".format(time.time() - t0))\n",
    "        return outputs, img_info\n",
    "\n",
    "    def visual(self, output, img_info, cls_conf=0.35):\n",
    "        ratio = img_info[\"ratio\"]\n",
    "        img = img_info[\"raw_img\"]\n",
    "        if output is None:\n",
    "            return img\n",
    "        output = output.cpu()\n",
    "\n",
    "        bboxes = output[:, 0:4]\n",
    "\n",
    "        # preprocessing: resize\n",
    "        bboxes /= ratio\n",
    "\n",
    "        cls = output[:, 6]\n",
    "        scores = output[:, 4] * output[:, 5]\n",
    "\n",
    "        vis_res = vis(img, bboxes, scores, cls, cls_conf, self.cls_names)\n",
    "        return vis_res\n",
    "\n",
    "    def visual_object_pose(self, output, img_info, cls_conf):\n",
    "        img = np.ascontiguousarray(img_info[\"img\"])\n",
    "        img_2d = copy.deepcopy(img)\n",
    "        im_cuboid = copy.deepcopy(img)\n",
    "        im_mask = copy.deepcopy(img)\n",
    "        camera_matrix = self.cad_models.camera_matrix\n",
    "        if output is None:\n",
    "            return img\n",
    "        output = output.cpu()\n",
    "        if isinstance(camera_matrix, dict):\n",
    "            camera_matrix = camera_matrix['camera_uw']\n",
    "        for ind in range(output.shape[0]):\n",
    "            pose = {}\n",
    "            pose['xy'] = output[ind, 11:13]\n",
    "            rotation_vec, translation_vec = decode_rotation_translation(output[ind], camera_matrix=camera_matrix)\n",
    "            pose[\"rotation_vec\"] = rotation_vec\n",
    "            pose[\"translation_vec\"] = translation_vec\n",
    "            cls = output[ind][-1]\n",
    "            color = colors(cls)\n",
    "            plot_one_box(output[ind], img_2d, im_cuboid=im_cuboid, im_mask=im_mask, color=color, object_pose=True, label=str(int(cls.numpy())),\n",
    "                  cad_models=self.cad_models, camera_matrix=camera_matrix, pose=pose, block_x=0, block_y=0, cls_names=self.cls_names, orig_shape=img.shape)\n",
    "        return [img, img_2d, im_cuboid, im_mask]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "exp = get_exp(exp_name=\"yolox-s-object-pose-ti-lite\")\n",
    "exp.num_classes = len(YCBV_CLASSES)\n",
    "exp.nmsthre = 0.3\n",
    "exp.test_conf = 0.3\n",
    "model = exp.get_model()\n",
    "weights = torch.load(os.path.join(model_root_path, 'best_ckpt.pth'), weights_only=True, map_location=DEVICE)\n",
    "model.load_state_dict(weights['model'], strict=True)\n",
    "#model.half()\n",
    "model.eval()\n",
    "model.to(\"cpu\")\n",
    "info = get_model_info(model, exp.test_size)\n",
    "logger.info(\"Model Summary: {}\".format(info))\n",
    "model.to(DEVICE)\n",
    "model.half()\n",
    "\n",
    "predictor = Predictor(model, exp, cls_names=YCBV_CLASSES, device=DEVICE, task=\"object_pose\", fp16=True)\n",
    "\n",
    "imagePath = '/Users/jon/NTNU Dropbox/WiseSync/NAS/Datasets/YCB-V/train_real/000000/rgb/000001.png'\n",
    "outputs, img_info = predictor.inference(imagePath)\n",
    "vis_res = predictor.visual_object_pose(outputs[0], img_info, cls_conf=0)\n",
    "\n",
    "#convert float to integers for plotting\n",
    "vis_res = [np.array(img).astype(np.uint8) for img in vis_res]\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15, 7))\n",
    "ax[0].imshow(vis_res[0])\n",
    "ax[0].set_title('Raw image')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(vis_res[1])\n",
    "ax[1].set_title('2D Bounding Box')\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(vis_res[2])\n",
    "ax[2].set_title('Cuboid')\n",
    "ax[2].axis('off')\n",
    "ax[3].imshow(vis_res[3])\n",
    "ax[3].set_title('Mask')\n",
    "ax[3].axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "so = rt.SessionOptions()\n",
    "providers = ['CPUExecutionProvider']\n",
    "session = rt.InferenceSession(os.path.join(model_root_path,\"yolox_s_object_pose_ti_lite.onnx\"),providers=providers ,sess_options=so)\n",
    "\n",
    "\n",
    "#Print input/ouput names and shapes\n",
    "print(\"Input Name:\", session.get_inputs()[0].name)\n",
    "print(\"Input Shape:\", session.get_inputs()[0].shape)\n",
    "print(\"Input Type:\", session.get_inputs()[0].type)\n",
    "print(\"Output Name:\", session.get_outputs()[0].name)\n",
    "print(\"Output Shape:\", session.get_outputs()[0].shape)\n",
    "print(\"Output Type:\", session.get_outputs()[0].type)\n",
    "\n",
    "imagePath = '/Users/jon/NTNU Dropbox/WiseSync/NAS/Datasets/YCB-V/train_real/000000/rgb/000000.png'\n",
    "input_size = (1, 3, 480, 640)\n",
    "\n",
    "image = Image.open(imagePath).convert('RGB')\n",
    "new_img_width = input_size[3]\n",
    "new_img_height = float(new_img_width) / image.size[0] * image.size[1]\n",
    "        \n",
    "# Resize\n",
    "img_resized = image.resize((int(new_img_width), int(new_img_height)), Image.LANCZOS)\n",
    "crop_x = (img_resized.size[0] - input_size[3]) / 2\n",
    "crop_y = (img_resized.size[1] - input_size[2]) / 2\n",
    "\n",
    "crop_img = img_resized.crop((crop_x, crop_y, crop_x+input_size[3], crop_y+input_size[2]))\n",
    "assert crop_img.size[0] == input_size[3] and crop_img.size[1] == input_size[2]\n",
    "\n",
    "#HWC -> CHW\n",
    "crop_img = np.array(crop_img).transpose(2, 0, 1)\n",
    "\n",
    "img = crop_img.astype(np.float32)\n",
    "ort_inputs = {session.get_inputs()[0].name: img[None, :, :, :]}\n",
    "start = time.time()\n",
    "output = session.run(None, ort_inputs)\n",
    "end = time.time()\n",
    "print(\"Inference time: \", end-start)\n",
    "\n",
    "dets = output[0]\n",
    "#image = np.array(image)\n",
    "draw_img1 = draw_bbox_2d(np.array(image), dets, YCBV_CLASSES, 0.0)\n",
    "\n",
    "draw_img2 = draw_obj_pose(np.array(image), dets, class_names=YCBV_CLASSES, class_to_cuboid=ycbv_vertices[:, None, :] * vertices_order, camera_matrix=ycbv_camera_matrix, conf_thres=0.0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 7))\n",
    "ax[0].imshow(draw_img1)\n",
    "ax[0].set_title('Bounding Boxes')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(draw_img2)\n",
    "ax[1].set_title('Object Poses')\n",
    "ax[1].axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "cx = 312.9869\n",
    "cy = 241.3109\n",
    "fx = 1066.778\n",
    "fy = 1067.487\n",
    "width = 640\n",
    "height = 480\n",
    "depth_scale = 0.1  # 若需要深度資訊，可另外保留此值\n",
    "\n",
    "vertices = ycbv_vertices[:, None, :] * vertices_order\n",
    "\n",
    "# 相機內參矩陣 (Camera Intrinsic Matrix)\n",
    "camera_intrinsic = np.array([\n",
    "    [fx,   0,  cx],\n",
    "    [ 0,  fy,  cy],\n",
    "    [ 0,   0,   1]\n",
    "], dtype=float)\n",
    "\n",
    "print(\"Updated camera intrinsic matrix:\\n\", camera_intrinsic)\n",
    "\n",
    "def draw_2d_bbox(img, bbox, color=(0,255,0), thickness=2):\n",
    "    print(bbox)\n",
    "    x, y, w, h = bbox\n",
    "    x1, y1, x2, y2 = int(x), int(y), int(x+w), int(y+h)\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n",
    "    return img\n",
    "\n",
    "def draw_3d_box(img, corners_2d, color=(255,0,0), thickness=2):\n",
    "    # corners_2d: shape=(2,8)\n",
    "    corners_2d = corners_2d.T  # shape: (8,2)\n",
    "    \n",
    "    # 新增以下一行，確保座標是整數\n",
    "    corners_2d = corners_2d.astype(int)\n",
    "\n",
    "    # front face: 0,1,2,3; rear face:4,5,6,7\n",
    "    front_face = [0,1,2,3,0]\n",
    "    back_face = [4,5,6,7,4]\n",
    "    for i in range(len(front_face)-1):\n",
    "        cv2.line(img, tuple(corners_2d[front_face[i]]), tuple(corners_2d[front_face[i+1]]), color, thickness)\n",
    "        cv2.line(img, tuple(corners_2d[back_face[i]]), tuple(corners_2d[back_face[i+1]]), color, thickness)\n",
    "        cv2.line(img, tuple(corners_2d[front_face[i]]), tuple(corners_2d[back_face[i]]), color, thickness)\n",
    "    return img\n",
    "\n",
    "def project_to_image(pts_3d, R, T, camera_intrinsic):\n",
    "    # pts_3d: shape=(3,N), R: 3x3, T: 3x1\n",
    "    # 將模型座標下的點透過 R, T轉到攝影機坐標系下\n",
    "    # 假設物件已定義在模型座標(0,0,0)為中心, R和T將model坐標轉到cam坐標\n",
    "    # pts_cam = R * pts_3d + T\n",
    "    #translat before rotation\n",
    "    pts_cam = R @ pts_3d + T.reshape(3,1)\n",
    "    # 投影到2D\n",
    "    pts_2d = camera_intrinsic @ pts_cam\n",
    "    pts_2d = pts_2d[:2,:] / pts_2d[2,:]\n",
    "    return pts_2d\n",
    "\n",
    "# 讀取COCO格式的註解檔 (請更新成實際檔名)\n",
    "root_path = '/Users/jon/NTNU Dropbox/WiseSync/NAS/Datasets/YCB-V/train_real'\n",
    "json_path = '/Users/jon/NTNU Dropbox/WiseSync/NAS/Datasets/YCB-V/annotations/instances_train_real.json'\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "images = data['images']\n",
    "annotations = data['annotations']\n",
    "\n",
    "# 將annotation依image_id整理\n",
    "ann_by_img = {}\n",
    "for ann in annotations:\n",
    "    img_id = ann['image_id']\n",
    "    if img_id not in ann_by_img:\n",
    "        ann_by_img[img_id] = []\n",
    "    ann_by_img[img_id].append(ann)\n",
    "\n",
    "# 選定一張圖來展示 (例如第一張)\n",
    "target_img_info = images[0]\n",
    "img_file = Path(target_img_info['image_folder'])/'rgb'/ target_img_info['file_name']\n",
    "img_file = os.path.join(root_path, img_file)\n",
    "print(f\"Image file: {img_file}\")\n",
    "img = cv2.imread(str(img_file))\n",
    "if img is None:\n",
    "    print(f\"Image not found: {img_file}\")\n",
    "    \n",
    "img_2d = img.copy()\n",
    "img_3d = img.copy()\n",
    "\n",
    "if target_img_info['id'] in ann_by_img:\n",
    "    for ann in ann_by_img[target_img_info['id']]:\n",
    "        # 畫2D BBox\n",
    "        category_id = ann['category_id']\n",
    "        bbox = ann['bbox']\n",
    "        draw_2d_bbox(img_2d, bbox, color=(0,255,0))\n",
    "\n",
    "        # 取得R和T\n",
    "        R_flat = ann['R'] # 9 elements\n",
    "        R_matrix = np.array(R_flat).reshape(3,3)\n",
    "        T_vec = np.array(ann['T']) # 3 elements\n",
    "\n",
    "        # 將3D框投影到2D\n",
    "        objject_vertices = vertices[category_id].T  # shape: (3,8)\n",
    "        corners_2d = project_to_image(objject_vertices, R_matrix, T_vec, camera_intrinsic)\n",
    "        draw_3d_box(img_3d, corners_2d, color=(255,0,0))\n",
    "\n",
    "# 顯示兩張圖：左邊有2D BBox，右邊有3D投影框\n",
    "img_2d_rgb = cv2.cvtColor(img_2d, cv2.COLOR_BGR2RGB)\n",
    "img_3d_rgb = cv2.cvtColor(img_3d, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"2D Bounding Boxes\")\n",
    "plt.imshow(img_2d_rgb)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"3D Projection\")\n",
    "plt.imshow(img_3d_rgb)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/jon/NTNU Dropbox/WiseSync/NAS/Datasets/nuScenes/annotations_6sweeps/mini_train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 106\u001b[0m\n\u001b[1;32m    104\u001b[0m root_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/jon/NTNU Dropbox/WiseSync/NAS/Datasets/nuScenes/v1.0-mini\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    105\u001b[0m json_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/jon/NTNU Dropbox/WiseSync/NAS/Datasets/nuScenes/annotations_6sweeps/mini_train.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    107\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m    109\u001b[0m images \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/workspace/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/jon/NTNU Dropbox/WiseSync/NAS/Datasets/nuScenes/annotations_6sweeps/mini_train.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "import math\n",
    "\n",
    "cx = 312.9869\n",
    "cy = 241.3109\n",
    "fx = 1066.778\n",
    "fy = 1067.487\n",
    "width = 640\n",
    "height = 480\n",
    "depth_scale = 0.1  # 若需要深度資訊，可另外保留此值\n",
    "\n",
    "\n",
    "def draw_2d_bbox(img, bbox, color=(0,255,0), thickness=2):\n",
    "    print(bbox)\n",
    "    x, y, w, h = bbox\n",
    "    x1, y1, x2, y2 = int(x), int(y), int(x+w), int(y+h)\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n",
    "    return img\n",
    "\n",
    "def draw_3d_box(img, corners_2d, color=(255,0,0), thickness=2):\n",
    "    # corners_2d: shape=(2,8)\n",
    "    corners_2d = corners_2d.T  # shape: (8,2)\n",
    "    \n",
    "    # 新增以下一行，確保座標是整數\n",
    "    corners_2d = corners_2d.astype(int)\n",
    "\n",
    "    # front face: 0,1,2,3; rear face:4,5,6,7\n",
    "    front_face = [0,1,2,3,0]\n",
    "    back_face = [4,5,6,7,4]\n",
    "    for i in range(len(front_face)-1):\n",
    "        cv2.line(img, tuple(corners_2d[front_face[i]]), tuple(corners_2d[front_face[i+1]]), color, thickness)\n",
    "        cv2.line(img, tuple(corners_2d[back_face[i]]), tuple(corners_2d[back_face[i+1]]), color, thickness)\n",
    "        cv2.line(img, tuple(corners_2d[front_face[i]]), tuple(corners_2d[back_face[i]]), color, thickness)\n",
    "    return img\n",
    "\n",
    "def project_to_image(pts_3d, R, T, camera_intrinsic):\n",
    "    # pts_3d: shape=(3,N), R: 3x3, T: 3x1\n",
    "    # 將模型座標下的點透過 R, T轉到攝影機坐標系下\n",
    "    # 假設物件已定義在模型座標(0,0,0)為中心, R和T將model坐標轉到cam坐標\n",
    "    # pts_cam = R * pts_3d + T\n",
    "    #translat before rotation\n",
    "    pts_cam = R @ pts_3d + T.reshape(3,1)\n",
    "    # 投影到2D\n",
    "    pts_2d = camera_intrinsic @ pts_cam\n",
    "    pts_2d = pts_2d[:2,:] / pts_2d[2,:]\n",
    "    return pts_2d\n",
    "\n",
    "def get_camera_matrix(calib):\n",
    "    \"\"\"\n",
    "    從 calib (3×4) 中擷取相機內參 (3×3)。\n",
    "    calib 一般形如：\n",
    "    [\n",
    "      [fx,  0, cx, Tx],\n",
    "      [ 0, fy, cy, Ty],\n",
    "      [ 0,  0,  1,  0]\n",
    "    ]\n",
    "    回傳 camera_matrix (3×3)。\n",
    "    \"\"\"\n",
    "    # 將 calib 轉為 numpy array，方便切片\n",
    "    calib_array = np.array(calib)\n",
    "    # 取前 3 個欄位，即為 camera intrinsic matrix\n",
    "    camera_matrix = calib_array[:, :3]\n",
    "    return camera_matrix\n",
    "\n",
    "def rotation_y_to_matrix(rotation_y_rad):\n",
    "    \"\"\"\n",
    "    給定繞 y 軸的旋轉角(弧度)，回傳 3x3 旋轉矩陣 (numpy array)。\n",
    "    \"\"\"\n",
    "    c = math.cos(rotation_y_rad)\n",
    "    s = math.sin(rotation_y_rad)\n",
    "    R = np.array([\n",
    "        [ c,  0,  s],\n",
    "        [ 0,  1,  0],\n",
    "        [-s,  0,  c]\n",
    "    ], dtype=np.float32)\n",
    "    return R\n",
    "\n",
    "def get_3d_box_corners_from_dim(dim):\n",
    "    \"\"\"\n",
    "    根據 dim = [height, width, length]\n",
    "    回傳 shape = (3, 8) 的 3D bounding box 8 個頂點坐標 (x, y, z)，\n",
    "    物件中心位於 (0, 0, 0)。\n",
    "    \"\"\"\n",
    "    h, w, l = dim[0]*1000, dim[1]*1000, dim[2]*1000\n",
    "    \n",
    "    # 以物件中心 (0,0,0) 為原點\n",
    "    # x軸方向: ±(l/2), y軸方向: ±(h/2), z軸方向: ±(w/2)\n",
    "    # （您可依照實際定義更改：像是把 y=0 設在底部）\n",
    "    # x軸: ±l/2, y軸: [0 ~ -h], z軸: ±w/2\n",
    "    x_corners = [ l/2,  l/2, -l/2, -l/2,  l/2,  l/2, -l/2, -l/2]\n",
    "    y_corners = [ 0,     0,     0,     0,  -h,   -h,   -h,   -h ]\n",
    "    z_corners = [ w/2, -w/2, -w/2,  w/2,  w/2, -w/2, -w/2,  w/2]\n",
    "    \n",
    "    # 組合為 (3, 8) 的 numpy array: [[x1..x8],[y1..y8],[z1..z8]]\n",
    "    corners_3d = np.vstack((x_corners, y_corners, z_corners))\n",
    "    return corners_3d\n",
    "\n",
    "# 讀取COCO格式的註解檔 (請更新成實際檔名)\n",
    "root_path = '/Users/jon/NTNU Dropbox/WiseSync/NAS/Datasets/nuScenes/v1.0-mini'\n",
    "json_path = '/Users/jon/NTNU Dropbox/WiseSync/NAS/Datasets/nuScenes/annotations_6sweeps/mini_train.json'\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "images = data['images']\n",
    "annotations = data['annotations']\n",
    "\n",
    "# 將annotation依image_id整理\n",
    "ann_by_img = {}\n",
    "for ann in annotations:\n",
    "    img_id = ann['image_id']\n",
    "    if img_id not in ann_by_img:\n",
    "        ann_by_img[img_id] = []\n",
    "    ann_by_img[img_id].append(ann)\n",
    "\n",
    "# 選定一張圖來展示 (例如第一張)\n",
    "target_img_info = images[0]\n",
    "img_file = target_img_info['file_name']\n",
    "img_file = os.path.join(root_path, img_file)\n",
    "print(f\"Image file: {img_file}\")\n",
    "img = cv2.imread(str(img_file))\n",
    "if img is None:\n",
    "    print(f\"Image not found: {img_file}\")\n",
    "    \n",
    "img_2d = img.copy()\n",
    "img_3d = img.copy()\n",
    "\n",
    "if target_img_info['id'] in ann_by_img:\n",
    "    for ann in ann_by_img[target_img_info['id']]:\n",
    "        # 畫2D BBox\n",
    "        category_id = ann['category_id']\n",
    "        bbox = ann['bbox']\n",
    "        draw_2d_bbox(img_2d, bbox, color=(0,255,0))\n",
    "\n",
    "        # 取得R和T\n",
    "        R_flat = ann['R'] # 9 elements\n",
    "        R_matrix = np.array(R_flat).reshape(3,3)\n",
    "        T_vec = np.array(ann['T']) # 3 elements\n",
    "\n",
    "        # 將3D框投影到2D\n",
    "        objject_vertices = get_3d_box_corners_from_dim(ann['dim'])\n",
    "        camera_intrinsic = get_camera_matrix(target_img_info['calib'])\n",
    "        corners_2d = project_to_image(objject_vertices, R_matrix, T_vec, camera_intrinsic)\n",
    "        draw_3d_box(img_3d, corners_2d, color=(255,0,0))\n",
    "\n",
    "# 顯示兩張圖：左邊有2D BBox，右邊有3D投影框\n",
    "img_2d_rgb = cv2.cvtColor(img_2d, cv2.COLOR_BGR2RGB)\n",
    "img_3d_rgb = cv2.cvtColor(img_3d, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"2D Bounding Boxes\")\n",
    "plt.imshow(img_2d_rgb)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"3D Projection\")\n",
    "plt.imshow(img_3d_rgb)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
